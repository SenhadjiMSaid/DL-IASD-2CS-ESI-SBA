{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10776021,
          "sourceType": "datasetVersion",
          "datasetId": 6685889
        }
      ],
      "dockerImageVersionId": 30886,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Training MLP from scratch  on mnist dataset ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SenhadjiMSaid/DL-IASD-2CS-ESI-SBA/blob/main/Training_MLP_from_scratch_on_mnist_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "senhadjimohamedsaid_mnist_dataset_path = kagglehub.dataset_download('senhadjimohamedsaid/mnist-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Wu7eCEW_QrvA"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Training an MLP from scratch\n",
        "\n",
        "**Nom** : Senhadji M Said"
      ],
      "metadata": {
        "id": "oNZXFF3PQrvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Necessary Packages\n"
      ],
      "metadata": {
        "id": "5YnGLvTaQrvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:25:16.761852Z",
          "iopub.execute_input": "2025-02-19T07:25:16.762092Z",
          "iopub.status.idle": "2025-02-19T07:25:19.468664Z",
          "shell.execute_reply.started": "2025-02-19T07:25:16.762069Z",
          "shell.execute_reply": "2025-02-19T07:25:19.467778Z"
        },
        "id": "96Sp2rzYQrvH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- Initialization\n",
        "Write the function ``init_params(nx, nh, ny)``"
      ],
      "metadata": {
        "id": "fLTgJsJIQrvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params(nx, nh, ny):\n",
        "    W1 = np.random.normal(loc=0, scale=0.3, size=(nh, nx+1)).astype(np.float32)\n",
        "    W2 = np.random.normal(loc=0, scale=0.3, size=(ny, nh+1)).astype(np.float32)\n",
        "    return [W1, W2]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:25:26.91515Z",
          "iopub.execute_input": "2025-02-19T07:25:26.915486Z",
          "iopub.status.idle": "2025-02-19T07:25:26.920282Z",
          "shell.execute_reply.started": "2025-02-19T07:25:26.91546Z",
          "shell.execute_reply": "2025-02-19T07:25:26.919388Z"
        },
        "id": "2EQpThHHQrvJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward propagation"
      ],
      "metadata": {
        "id": "HHmR2KeTQrvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation Functions:\n",
        "- `tanh(z)` : Hyperbolic tangent activation function\n",
        "- `sigmoid(z)` : Standard sigmoid function\n",
        "- `softmax(z)` : Converts logits into probabilities, with a numerical stability trick `z.max(axis=0)` to prevent overflow.\n",
        ""
      ],
      "metadata": {
        "id": "J2E8icsQQrvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh(z):\n",
        "    return np.tanh(z)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:25:30.717789Z",
          "iopub.execute_input": "2025-02-19T07:25:30.718076Z",
          "iopub.status.idle": "2025-02-19T07:25:30.72158Z",
          "shell.execute_reply.started": "2025-02-19T07:25:30.718055Z",
          "shell.execute_reply": "2025-02-19T07:25:30.720825Z"
        },
        "id": "HUQXm7qMQrvK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:25:33.088755Z",
          "iopub.execute_input": "2025-02-19T07:25:33.089095Z",
          "iopub.status.idle": "2025-02-19T07:25:33.092833Z",
          "shell.execute_reply.started": "2025-02-19T07:25:33.089067Z",
          "shell.execute_reply": "2025-02-19T07:25:33.091913Z"
        },
        "id": "-fGvpsouQrvL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "    t = np.exp(z - np.max(z, axis=0, keepdims=True))\n",
        "    return t / np.sum(t, axis=0, keepdims=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:25:41.776773Z",
          "iopub.execute_input": "2025-02-19T07:25:41.777183Z",
          "iopub.status.idle": "2025-02-19T07:25:41.782703Z",
          "shell.execute_reply.started": "2025-02-19T07:25:41.777151Z",
          "shell.execute_reply": "2025-02-19T07:25:41.781722Z"
        },
        "id": "vuyIyduTQrvM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `forward` function\n",
        "1. **inputs**:\n",
        "   - `params` : List of wight matrices for each layer.\n",
        "   - `X`: Input data of shape `(n_batch, nx)`\n",
        "   - `activation`: List of activation functions to be used for each layer\n",
        "2. **Processing**:\n",
        "   - The input `X` is transposed `(Y = X.T)` to match matrix multiplication dimensions.\n",
        "   - The function loops through each weight matrix (`W`) and activation function (`activation`).\n",
        "   - **Bias Handling**: Adds a row of ones to Y to account for bias terms.\n",
        "   - Computes `Z = W @ Y` (weighted sum).\n",
        "   - Applies the activation function : `Y = activation(Z)`.\n",
        "   - Stores both `Z` (pre-activation) and `Y` (post-activation) in `outputs`.\n",
        "3. **Returns**:\n",
        "   - `outputs`: A list of intermediate values, as `[Z, Y]`."
      ],
      "metadata": {
        "id": "bnKZXsDZQrvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(params, X, activations):\n",
        "    Y = X.T\n",
        "    outputs = []\n",
        "\n",
        "    for W, activation in zip(params, activations):\n",
        "        Y = np.vstack([np.ones((1, Y.shape[1])), Y])\n",
        "        Z = W @ Y  # Linear transformation\n",
        "        Y = activation(Z)\n",
        "        outputs.append([Z, Y])\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:26:40.39978Z",
          "iopub.execute_input": "2025-02-19T07:26:40.400113Z",
          "iopub.status.idle": "2025-02-19T07:26:40.40498Z",
          "shell.execute_reply.started": "2025-02-19T07:26:40.400089Z",
          "shell.execute_reply": "2025-02-19T07:26:40.403992Z"
        },
        "id": "vYv7pIcuQrvM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss & Accuracy\n",
        "### Loss Calculation (Categorical Cross-Entropy)\n",
        "For multi-class classification, we typically use categorical cross-entropy loss, which is defined as:\n",
        "$$ L = - \\frac{1}{N} \\sum_{i=1}^{N}{\\sum_{j=1}^{C}{y_{i,j}log(\\hat{y}_{i,j})}}  $$\n",
        "where:\n",
        "  - $N$ is the number of samples.\n",
        "  - $C$ is the number of classes.\n",
        "  - $y_{i,j}$ is the actual label for sample $i$, class $j$.\n",
        "  - $\\hat{y}_{i,j}$ is the predicted probability for sample $i$, class $j$.\n",
        "\n",
        "### Accuracy Calculation\n",
        "$$ \\text{Accurancy} = \\frac{1}{N}\\sum_{i=1}^N{1(\\arg \\max{\\hat{y_i}} = \\arg \\max{y_i})} $$\n",
        "where:\n",
        "- $\\arg \\max{y_i}$ : finds the index of the correct class (ground truth label)\n",
        "- $\\arg \\max{\\hat{y_i}}$ : finds the index of the predicted class\n",
        "- $1(.)$ : s an indicator function that returns $1$ if the predicted class matches the true class, otherwise $0$.\n"
      ],
      "metadata": {
        "id": "LK9lFwB-QrvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_accuracy(y_hat, y):\n",
        "    loss = -np.mean(np.log(np.sum(y_hat * y, axis=1)))\n",
        "    accuracy = np.mean(np.argmax(y_hat, axis=1) == np.argmax(y, axis=1))\n",
        "    return loss,accuracy"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:26:47.126803Z",
          "iopub.execute_input": "2025-02-19T07:26:47.127108Z",
          "iopub.status.idle": "2025-02-19T07:26:47.131665Z",
          "shell.execute_reply.started": "2025-02-19T07:26:47.127085Z",
          "shell.execute_reply": "2025-02-19T07:26:47.130722Z"
        },
        "id": "y3BvgAHaQrvN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backward propagation\n",
        "**Inputs**:\n",
        "  - `X`: Input data of shape $(m, nx)$\n",
        "  - `params`: List of weight matrices ``\n",
        "  - `outputs`: List of forward pass outputs `[[Z1, A1], [Z2, A2]]`\n",
        "  - `Y`:   Ground truth labels\n",
        "\n",
        "**Step 1: Preparing Activations**\n",
        "- Adds a bias row (ones) to `A1` and `X` to match dimensions with weight matrices.\n",
        "- `outputs[-2][1]` refers to `A1`, the activation from the hidden layer.\n",
        "\n",
        "**Step 2: Compute Gradients for Output Layer**\n",
        "- Computes the output layer error\n",
        "  $$ dZ^{[2]} = \\hat{Y} - Y $$\n",
        "- Computes the gradient for `W2`:\n",
        "  $$ dW^{[2]} = dZ^{[2]}.A^{[1]T} $$\n",
        "\n",
        "**Step 3: Compute Gradients for Hidden Layer**\n",
        "- ``outputs[-2][0]`` refers to Z1, the pre-activation of the hidden layer.\n",
        "- Applies the tanh function to retrieve `A1` for the derivative.\n",
        "  $$ dZ^{[1]} = (W^{[2]T} \\cdot dZ^{[2]}) * (1 - {A^{[1]}}^2) $$\n",
        "\n",
        "**Step 4: Compute Gradients for First Layer**\n",
        "Computes\n",
        "$$ dW^{[1]} = dZ^{[1]} \\cdot X^T $$\n",
        "\n",
        "**Final Return**\n",
        "```python\n",
        "return gradients\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "PZELdEI0QrvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward(X, params, outputs, Y):\n",
        "\n",
        "    # step 1\n",
        "    outputs[-2][1] = np.vstack([np.ones(outputs[-2][1].shape[1]),outputs[-2][1]]) # dA\n",
        "    X = np.vstack([np.ones(X.shape[0]),X.T])\n",
        "\n",
        "    # step 2\n",
        "    gradients = {}\n",
        "\n",
        "    gradients[\"dZ2\"] = outputs[-1][1] - Y.T # (ny,m) - (ny,m) = (ny,m)\n",
        "    gradients[\"dW2\"] = gradients[\"dZ2\"] @ outputs[-2][1].T # (ny,m) * (m,nh+1) = (ny,nh+1)\n",
        "\n",
        "\t# step 3\n",
        "    t = tanh(outputs[-2][0]) # (nh,m)\n",
        "    gradients[\"dZ1\"] = (params[-1].T[1:] @ gradients[\"dZ2\"]) * (1 - t ** 2)\n",
        "    # (nh,ny) @ (ny,m) * (nh,m) = (nh,m)\n",
        "    # step 4\n",
        "    gradients[\"dW1\"] = gradients[\"dZ1\"] @ X.T\n",
        "    # (nh,m) @ (m,nx+1) = (nh,nx+1)\n",
        "\n",
        "    return gradients"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:26:52.101025Z",
          "iopub.execute_input": "2025-02-19T07:26:52.101369Z",
          "iopub.status.idle": "2025-02-19T07:26:52.107214Z",
          "shell.execute_reply.started": "2025-02-19T07:26:52.10134Z",
          "shell.execute_reply": "2025-02-19T07:26:52.106425Z"
        },
        "id": "8nMpOOEnQrvO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent\n",
        "**Stochastic Gradient Descent** (SGD) updates the parameters using the formula:\n",
        "$$ W = W - \\eta \\cdot \\nabla W $$\n",
        "where:\n",
        "- $ W $ are the weight matrices (`params`)\n",
        "- $ \\eta $  is the learning rate (`eta`)\n",
        "- $ \\nabla W $  are the computed gradients (`grads`)"
      ],
      "metadata": {
        "id": "MiVPU7FmQrvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(params, grads, eta):\n",
        "    params[0] = params[0] - eta * grads[\"dW1\"]\n",
        "    params[1] = params[1] - eta * grads[\"dW2\"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:26:56.533173Z",
          "iopub.execute_input": "2025-02-19T07:26:56.533538Z",
          "iopub.status.idle": "2025-02-19T07:26:56.537787Z",
          "shell.execute_reply.started": "2025-02-19T07:26:56.533512Z",
          "shell.execute_reply": "2025-02-19T07:26:56.536875Z"
        },
        "id": "9L9m6nPzQrvP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n"
      ],
      "metadata": {
        "id": "fesYj7-TQrvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### utility functions"
      ],
      "metadata": {
        "id": "aXOswOGsQrvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(a):\n",
        "    b = np.zeros((a.size, a.max() + 1))\n",
        "    b[np.arange(a.size), a] = 1\n",
        "    return b"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:27:01.554132Z",
          "iopub.execute_input": "2025-02-19T07:27:01.554501Z",
          "iopub.status.idle": "2025-02-19T07:27:01.558665Z",
          "shell.execute_reply.started": "2025-02-19T07:27:01.554476Z",
          "shell.execute_reply": "2025-02-19T07:27:01.557633Z"
        },
        "id": "jDOWHDXGQrvP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(params, X):\n",
        "    outputs = forward(params, X, [tanh,softmax])\n",
        "    y_hat = outputs[-1][-1]\n",
        "    y_hat = np.argmax(y_hat, axis=0)\n",
        "    return y_hat"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:27:05.082939Z",
          "iopub.execute_input": "2025-02-19T07:27:05.083237Z",
          "iopub.status.idle": "2025-02-19T07:27:05.087521Z",
          "shell.execute_reply.started": "2025-02-19T07:27:05.083195Z",
          "shell.execute_reply": "2025-02-19T07:27:05.086721Z"
        },
        "id": "89GhplapQrvP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def add_eps(params, eps=10e-4):\n",
        "    result = []\n",
        "\n",
        "    for param in params:\n",
        "        result.append(param + eps)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:27:08.13584Z",
          "iopub.execute_input": "2025-02-19T07:27:08.136133Z",
          "iopub.status.idle": "2025-02-19T07:27:08.140477Z",
          "shell.execute_reply.started": "2025-02-19T07:27:08.136112Z",
          "shell.execute_reply": "2025-02-19T07:27:08.139507Z"
        },
        "id": "qzmF6VdZQrvQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train function"
      ],
      "metadata": {
        "id": "ifAUhCHWQrvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import trange\n",
        "\n",
        "def train(X, Y, test_set=None,eta=0.01, epochs=50, batch_size=128, nh=32):\n",
        "    #  1 setup & initi\n",
        "    m,n = X.shape\n",
        "\n",
        "    ny = len(np.unique(Y))\n",
        "\n",
        "    Y = one_hot(Y)\n",
        "\n",
        "    if test_set is not None:\n",
        "        test_set = (test_set[0], one_hot(test_set[1]))\n",
        "\n",
        "    params = init_params(n,nh,ny)\n",
        "\n",
        "    # 2 Initialize History\n",
        "    history = {\n",
        "        \"accuracy\": [],\n",
        "        \"loss\":[],\n",
        "        \"test loss\":[],\n",
        "        \"test accuracy\":[]\n",
        "    }\n",
        "\n",
        "    real_grads = []\n",
        "    approx_grads = []\n",
        "\n",
        "\t# 3 Training Loop\n",
        "    for j in range(epochs):\n",
        "        idx = np.arange(m)\n",
        "        np.random.shuffle(idx)\n",
        "        X = X[idx]\n",
        "        Y = Y[idx]\n",
        "\n",
        "        batches_count = int(np.floor(m / batch_size))\n",
        "        # 4 mini-batch processing\n",
        "        t = trange(batches_count, desc='Bar desc', leave=True)\n",
        "\n",
        "        for i in t:\n",
        "\n",
        "            X_batch = X[i * batch_size:(i+1) * batch_size,:]\n",
        "            Y_batch = Y[i * batch_size:(i+1) * batch_size,:]\n",
        "\n",
        "            outputs = forward(params, X_batch, [tanh, softmax])\n",
        "            grads = backward(X_batch, params, outputs, Y_batch)\n",
        "\n",
        "            # 5 gradient approximation\n",
        "            outputs_p_eps = forward(add_eps(params, 10e-4), X_batch, [tanh, softmax])[-1][-1]\n",
        "            outputs_m_eps = forward(add_eps(params, -10e-4), X_batch, [tanh, softmax])[-1][-1]\n",
        "            approx_grad = (outputs_m_eps-outputs_p_eps) / (2 * 10e-4)\n",
        "\n",
        "            # 6 update parametes using SGD\n",
        "            real_grads.append(grads)\n",
        "            approx_grads.append(approx_grad)\n",
        "\n",
        "            sgd(params, grads,eta=eta)\n",
        "\n",
        "            # 7 compute metrics\n",
        "            if i % 50 == 0:\n",
        "                Y_hat = outputs[-1][1].T\n",
        "                loss, accuracy = loss_accuracy(Y_hat, Y_batch)\n",
        "\n",
        "                msg = f\"epoch = {j+1} | loss = {loss:.6f} | accuracy = {100 * accuracy:.2f}%\"\n",
        "                test_loss,test_accuracy = None,None\n",
        "\n",
        "                if test_set is not None:\n",
        "                    X_test,y_test = test_set\n",
        "                    y_test_hat = forward(params, X_test, [tanh, softmax])[-1][1].T\n",
        "                    test_loss, test_accuracy = loss_accuracy(y_test, y_test_hat)\n",
        "                    msg += f\" | test loss = {test_loss:.6f} | test accuracy = {100 * test_accuracy:.2f}%\"\n",
        "\n",
        "                if i % 50 == 0:\n",
        "                    t.set_description(msg)\n",
        "                    t.refresh()\n",
        "\n",
        "\t\t\t\t# 8 Store History\n",
        "                history[\"loss\"].append(loss)\n",
        "                history[\"accuracy\"].append(accuracy)\n",
        "\n",
        "                if test_set is not None:\n",
        "                    history[\"test loss\"].append(test_loss)\n",
        "                    history[\"test accuracy\"].append(test_accuracy)\n",
        "    return params,history,real_grads,approx_grads\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:27:12.079027Z",
          "iopub.execute_input": "2025-02-19T07:27:12.07934Z",
          "iopub.status.idle": "2025-02-19T07:27:12.099176Z",
          "shell.execute_reply.started": "2025-02-19T07:27:12.079316Z",
          "shell.execute_reply": "2025-02-19T07:27:12.098293Z"
        },
        "id": "odZ-uRz2QrvQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quick Breakdown of the Code\n",
        "1. **Setup & Initialization**\n",
        "   - Converts labels to one-hot encoding.\n",
        "   - Intializes parameters (`W1, W2`)\n",
        "   - Stores test data (if provided).\n",
        "2. **Initialize History for Tracking Metrics**\n",
        "   - `history`: Tracks loss and accuracy for training & test sets\n",
        "   - `real_grads`: Stores actual gradients from backpropagation.\n",
        "   - `approx_grads`: Stores numerical gradient approximations.\n",
        "3. **Training Loop**\n",
        "   - Shuffles data each epoch for better generalization.\n",
        "   - Divides data into mini-batches.\n",
        "4. **Mini-Batch Processing**\n",
        "   - Iterates over mini-batches.\n",
        "   - Performs forward pass to compute predictions.\n",
        "   - Computes gradients using backpropagation.\n",
        "5. **Gradient Approximation for Debugging**\n",
        "   - Computes numerical gradients using **finite difference approximation**:\n",
        "   $$ \\frac{f(x+\\epsilon) - f(x-\\epsilon)}{2 \\epsilon}  $$\n",
        "   - Compares backpropagation gradients vs. numerical gradients.\n",
        "6. **Update Parameters Using SGD**\n",
        "   - Stores real gradients.\n",
        "   - Stores approximated gradients for debugging.\n",
        "7. **Compute Metrics**\n",
        "   - Computes **loss & accuracy** for training batch.\n",
        "   - If test data is available, computes test loss & accuracy.\n",
        "   - Displays progress bar updates in real time.\n",
        "8. **Store History**\n",
        "   - Saves training & test metrics for plotting later."
      ],
      "metadata": {
        "id": "KdJXQin6QrvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graphing Accuracy & Loss"
      ],
      "metadata": {
        "id": "XsLBaPfOQrvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history[\"loss\"], label=\"Train Loss\")\n",
        "    if \"test loss\" in history:\n",
        "        plt.plot(history[\"test loss\"], label=\"Test Loss\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss Over Time\")\n",
        "\n",
        "    # plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "    if \"test accuracy\" in history:\n",
        "        plt.plot(history[\"test accuracy\"], label=\"Test Accuracy\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Accuracy Over Time\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Call function after training"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:27:17.00701Z",
          "iopub.execute_input": "2025-02-19T07:27:17.007345Z",
          "iopub.status.idle": "2025-02-19T07:27:17.013281Z",
          "shell.execute_reply.started": "2025-02-19T07:27:17.007319Z",
          "shell.execute_reply": "2025-02-19T07:27:17.012327Z"
        },
        "id": "UjY5ybfrQrvR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train on mnist handwritten digits\n",
        "### Load the dataset"
      ],
      "metadata": {
        "id": "zWl89-1gQrvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Dataset link** : https://www.kaggle.com/datasets/senhadjimohamedsaid/mnist-dataset/data"
      ],
      "metadata": {
        "id": "u2TdnBi3QrvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"mnist_train.csv\"\n",
        "print(file_path)\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"senhadjimohamedsaid/mnist-dataset\",\n",
        "  file_path,\n",
        "  # Provide any additional arguments like\n",
        "  # sql_query or pandas_kwargs. See the\n",
        "  # documenation for more information:\n",
        "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df.head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:33:10.342191Z",
          "iopub.execute_input": "2025-02-19T07:33:10.342531Z",
          "iopub.status.idle": "2025-02-19T07:33:14.435615Z",
          "shell.execute_reply.started": "2025-02-19T07:33:10.342506Z",
          "shell.execute_reply": "2025-02-19T07:33:14.434576Z"
        },
        "id": "GeAusapDQrvR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df[\"label\"].values\n",
        "X = df[df.columns[1:]].values"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:33:20.377969Z",
          "iopub.execute_input": "2025-02-19T07:33:20.378326Z",
          "iopub.status.idle": "2025-02-19T07:33:20.503975Z",
          "shell.execute_reply.started": "2025-02-19T07:33:20.378298Z",
          "shell.execute_reply": "2025-02-19T07:33:20.503243Z"
        },
        "id": "x8GYtEuUQrvS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=Y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:33:22.907784Z",
          "iopub.execute_input": "2025-02-19T07:33:22.908081Z",
          "iopub.status.idle": "2025-02-19T07:33:23.220788Z",
          "shell.execute_reply.started": "2025-02-19T07:33:22.908061Z",
          "shell.execute_reply": "2025-02-19T07:33:23.220036Z"
        },
        "id": "owvrVANGQrvS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show some images"
      ],
      "metadata": {
        "id": "Qezxv-YJQrvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_random_images(X,Y, nrows=3, ncols=3, real_lables = None):\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
        "    n = nrows * ncols\n",
        "\n",
        "    idx = np.arange(X.shape[0])\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:n]\n",
        "\n",
        "    X = X[idx]\n",
        "    Y = Y[idx]\n",
        "\n",
        "    if real_lables is not None:\n",
        "        real_lables = real_lables[idx]\n",
        "\n",
        "    i = 0\n",
        "    for row in axes:\n",
        "        for cell in row:\n",
        "            img = X[i].reshape(28,28)\n",
        "            cell.imshow(img,cmap=\"gray\")\n",
        "            if real_lables is None:\n",
        "                cell.set_title(f\"Label = {Y[i]}\")\n",
        "            else:\n",
        "                cell.set_title(f\"Label = {Y[i]} \\n Real Label = {real_lables[i]}\")\n",
        "            i += 1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:33:27.751074Z",
          "iopub.execute_input": "2025-02-19T07:33:27.751444Z",
          "iopub.status.idle": "2025-02-19T07:33:27.758074Z",
          "shell.execute_reply.started": "2025-02-19T07:33:27.751418Z",
          "shell.execute_reply": "2025-02-19T07:33:27.756847Z"
        },
        "id": "GITZj43iQrvS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_random_images(X,Y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:33:29.800039Z",
          "iopub.execute_input": "2025-02-19T07:33:29.800399Z",
          "iopub.status.idle": "2025-02-19T07:33:30.923688Z",
          "shell.execute_reply.started": "2025-02-19T07:33:29.800372Z",
          "shell.execute_reply": "2025-02-19T07:33:30.92281Z"
        },
        "id": "2-oucQC0QrvS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X = X / 255.0"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:33:35.180784Z",
          "iopub.execute_input": "2025-02-19T07:33:35.181066Z",
          "iopub.status.idle": "2025-02-19T07:33:35.338522Z",
          "shell.execute_reply.started": "2025-02-19T07:33:35.181045Z",
          "shell.execute_reply": "2025-02-19T07:33:35.337819Z"
        },
        "id": "ylbDzPXaQrvT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, Y, test_size=0.2,stratify=Y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:33:37.22333Z",
          "iopub.execute_input": "2025-02-19T07:33:37.223651Z",
          "iopub.status.idle": "2025-02-19T07:33:38.069126Z",
          "shell.execute_reply.started": "2025-02-19T07:33:37.223626Z",
          "shell.execute_reply": "2025-02-19T07:33:38.068387Z"
        },
        "id": "Wbam_aqCQrvT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "params, history, real_grads, approx_grads = train(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    test_set=(X_test,y_test),\n",
        "    eta=0.01,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    nh=64\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:38:53.872018Z",
          "iopub.execute_input": "2025-02-19T07:38:53.872359Z",
          "iopub.status.idle": "2025-02-19T07:40:37.758469Z",
          "shell.execute_reply.started": "2025-02-19T07:38:53.872335Z",
          "shell.execute_reply": "2025-02-19T07:40:37.757286Z"
        },
        "id": "a5jlf9ecQrvZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning graph\n"
      ],
      "metadata": {
        "id": "AV6sTW_LQrvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2)\n",
        "\n",
        "fig.set_size_inches(10,3)\n",
        "\n",
        "ax1.plot(np.arange(len(history['accuracy'])),history['accuracy'], label=\"train\")\n",
        "ax2.plot(np.arange(len(history['loss'])),history['loss'],label=\"train\")\n",
        "\n",
        "ax1.set_title(\"Train & Test set accuracy over time\")\n",
        "\n",
        "ax1.plot(np.arange(len(history['test accuracy'])),history['test accuracy'], label='test')\n",
        "ax2.plot(np.arange(len(history['test loss'])),history['test loss'], label=\"test\")\n",
        "\n",
        "ax2.set_title(\"Test & test set loss over time\")\n",
        "\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T07:48:41.522443Z",
          "iopub.execute_input": "2025-02-19T07:48:41.522819Z",
          "iopub.status.idle": "2025-02-19T07:48:42.010228Z",
          "shell.execute_reply.started": "2025-02-19T07:48:41.522794Z",
          "shell.execute_reply": "2025-02-19T07:48:42.009232Z"
        },
        "id": "2UJqDqGZQrvZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Learning Curves\n",
        "1. **Left Plot (Accuracy Over Time)**\n",
        "   * The blue curve represents training accuracy.\n",
        "   * The orange curve represents test accuracy.\n",
        "   * Both curves increase rapidly at the beginning and then stabilize close to 1.0.\n",
        "   * This indicates that your model is learning well and generalizing effectively.\n",
        "2. **Right Plot (Loss Over Time)**\n",
        "   * The blue curve represents training loss.\n",
        "   * The orange curve represents test loss.\n",
        "   * Both losses drop sharply in the early epochs and then stabilize at low values.\n",
        "   * This suggests the model is minimizing the error successfully.\n",
        "\n",
        "\n",
        "### Observations\n",
        "* **Good Convergence**: The training and test accuracy stabilize near 1.0, showing that the MLP has effectively learned the digit recognition task.\n",
        "* **No Overfitting**: The test accuracy remains close to training accuracy, indicating that the model generalizes well.\n",
        "* **Smooth Loss Reduction**: The loss curves decline steadily without major fluctuations, suggesting stable optimization.\n"
      ],
      "metadata": {
        "id": "hdaJVm03QrvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "jrZGeeepQrva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T08:05:17.439393Z",
          "iopub.execute_input": "2025-02-19T08:05:17.439717Z",
          "iopub.status.idle": "2025-02-19T08:05:17.443629Z",
          "shell.execute_reply.started": "2025-02-19T08:05:17.439693Z",
          "shell.execute_reply": "2025-02-19T08:05:17.442742Z"
        },
        "id": "xwMgQu-dQrva"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_hat = predict(params, X_train)\n",
        "y_test_hat = predict(params, X_test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T08:05:21.202175Z",
          "iopub.execute_input": "2025-02-19T08:05:21.202535Z",
          "iopub.status.idle": "2025-02-19T08:05:21.473731Z",
          "shell.execute_reply.started": "2025-02-19T08:05:21.20251Z",
          "shell.execute_reply": "2025-02-19T08:05:21.472969Z"
        },
        "id": "DVo9UPfeQrva"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_matrics(y, y_hat):\n",
        "\n",
        "    accuracy = accuracy_score(y, y_hat)\n",
        "    f1 = f1_score(y, y_hat, average=\"macro\")\n",
        "    precision = precision_score(y, y_hat, average=\"macro\")\n",
        "    recall = recall_score(y, y_hat, average=\"macro\")\n",
        "\n",
        "    return pd.Series({\n",
        "        \"accuracy\":accuracy,\n",
        "        \"f1_score\":f1,\n",
        "        \"precision\":precision,\n",
        "        \"recall\":recall\n",
        "    })"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T08:05:23.57556Z",
          "iopub.execute_input": "2025-02-19T08:05:23.575921Z",
          "iopub.status.idle": "2025-02-19T08:05:23.580712Z",
          "shell.execute_reply.started": "2025-02-19T08:05:23.575894Z",
          "shell.execute_reply": "2025-02-19T08:05:23.579922Z"
        },
        "id": "n2QN1GAAQrva"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_metrics = get_matrics(y_train, y_train_hat)\n",
        "test_metrics = get_matrics(y_test, y_test_hat)\n",
        "metrics = pd.DataFrame(data={\n",
        "    \"train\": train_metrics,\n",
        "    \"test\":test_metrics\n",
        "})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T08:05:29.790116Z",
          "iopub.execute_input": "2025-02-19T08:05:29.790422Z",
          "iopub.status.idle": "2025-02-19T08:05:29.82975Z",
          "shell.execute_reply.started": "2025-02-19T08:05:29.790399Z",
          "shell.execute_reply": "2025-02-19T08:05:29.829031Z"
        },
        "id": "YGgY8nN3Qrva"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T08:05:33.444167Z",
          "iopub.execute_input": "2025-02-19T08:05:33.444488Z",
          "iopub.status.idle": "2025-02-19T08:05:33.463178Z",
          "shell.execute_reply.started": "2025-02-19T08:05:33.444464Z",
          "shell.execute_reply": "2025-02-19T08:05:33.462372Z"
        },
        "id": "EGnjKGWyQrva"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y, y_hat):\n",
        "    cm = confusion_matrix(y, y_hat)\n",
        "    ax = sns.heatmap(data=cm, annot=True,cmap='Blues', fmt=',d')\n",
        "    ax.get_figure().set_size_inches(10,10)\n",
        "    return ax"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T08:10:35.609975Z",
          "iopub.execute_input": "2025-02-19T08:10:35.610369Z",
          "iopub.status.idle": "2025-02-19T08:10:35.614924Z",
          "shell.execute_reply.started": "2025-02-19T08:10:35.610339Z",
          "shell.execute_reply": "2025-02-19T08:10:35.613933Z"
        },
        "id": "PNG7qIfqQrvb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ax = plot_confusion_matrix(y_train, y_train_hat)\n",
        "ax.set_title(\"Train set confusion matrix\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T08:10:40.56388Z",
          "iopub.execute_input": "2025-02-19T08:10:40.564221Z",
          "iopub.status.idle": "2025-02-19T08:10:41.106394Z",
          "shell.execute_reply.started": "2025-02-19T08:10:40.564176Z",
          "shell.execute_reply": "2025-02-19T08:10:41.105432Z"
        },
        "id": "_rnySJUOQrvb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ax = plot_confusion_matrix(y_test, y_test_hat)\n",
        "ax.set_title(\"Test set confusion matrix\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T08:13:09.475438Z",
          "iopub.execute_input": "2025-02-19T08:13:09.4758Z",
          "iopub.status.idle": "2025-02-19T08:13:10.02788Z",
          "shell.execute_reply.started": "2025-02-19T08:13:09.475775Z",
          "shell.execute_reply": "2025-02-19T08:13:10.027016Z"
        },
        "id": "2gSALnd8Qrvb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Train and test Set Confusion Matrix\n",
        "\n",
        "**Observations**:\n",
        " * The matrix is nearly diagonal, meaning almost all predictions are correct.\n",
        " * The numbers on the diagonal indicate that the model correctly classified almost every sample for each digit.\n",
        " * There are **zero misclassifications**, meaning the model has 100% **accuracy on the training set**.\n",
        " * Unlike the training set, this matrix is not perfectly diagonal—some misclassifications are present.\n",
        " * The diagonal elements still contain high values, meaning the majority of the test samples were classified correctly.\n",
        "\n",
        "**Common Misclassifications:** <br>\n",
        "Digit 9 → 4, 5 <br>\n",
        "Digit 5 → 3, 8 <br>\n",
        "Digit 3 → 2, 5 <br>\n",
        "Digit 8 → 3, 5 <br>\n",
        "These errors are expected since some handwritten numbers look similar."
      ],
      "metadata": {
        "id": "PTASmNGsQrvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error analysis\n"
      ],
      "metadata": {
        "id": "9OyquHFuQrvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_ = X_test[y_test_hat != y_test]\n",
        "y_test_ = y_test[y_test_hat != y_test]\n",
        "y_test_hat_ = y_test_hat[y_test_hat != y_test]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T08:21:03.485285Z",
          "iopub.execute_input": "2025-02-19T08:21:03.485663Z",
          "iopub.status.idle": "2025-02-19T08:21:03.490721Z",
          "shell.execute_reply.started": "2025-02-19T08:21:03.485634Z",
          "shell.execute_reply": "2025-02-19T08:21:03.489864Z"
        },
        "id": "tlFFNmECQrvc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_random_images(X_test_,y_test_hat_,real_lables=y_test_)\n",
        "plt.tight_layout(pad=0.25)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-19T08:21:13.834076Z",
          "iopub.execute_input": "2025-02-19T08:21:13.834413Z",
          "iopub.status.idle": "2025-02-19T08:21:15.289464Z",
          "shell.execute_reply.started": "2025-02-19T08:21:13.834385Z",
          "shell.execute_reply": "2025-02-19T08:21:15.288726Z"
        },
        "id": "u1jhXO3hQrvc"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}